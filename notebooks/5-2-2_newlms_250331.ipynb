{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 들어가며"],"metadata":{"id":"RqK3G23OKnhW"}},{"cell_type":"markdown","source":["**[아이스브레이킹] 대표적인 Regularization 기법에는 L1 regularization과 L2 regularization이 있다고 합니다. 1과 2는 무엇이 다른 걸까요? 정답을 맞힐 필요는 없이, 떠오르는 생각을 자유롭게 써 봅시다. 2가 1보다 더 좋은 걸까요?**\n","\n","<details>\n","<summary>💡예시답안 확인하기💡</summary>\n","\n","L1과 L2 regularization은 비슷하지만 서로 다른 특징을 가지고 있답니다. 이후 스텝에서 자세히 알아봅시다!\n","2가 1보다 더 좋고 이런 건 아닙니다...🤣\n","<details>"],"metadata":{"id":"zW_LRRf5Knfm"}},{"cell_type":"markdown","source":["## 학습 목표\n","---\n","- 정칙화(Regularization)의 개념을 이해하고 정규화(Normalization)와 구분합니다.\n","- L1 regularization과 L2 regularization의 차이를 설명합니다.\n","- 실습을 통하여 Lp norm, Dropout, Batch Normalization에 대해 학습합니다."],"metadata":{"id":"1OmVPCdyKndP"}},{"cell_type":"markdown","source":["## 목차\n","---\n","1. 들어가며\n","2. Regularization과 Normalization\n","3. L1 Regularization\n","4. L2 Regularization\n","5. Extra : Lp norm\n","6. Dropout\n","7. Batch Normalization"],"metadata":{"id":"vGeG6Zm0KnbG"}},{"cell_type":"markdown","source":["# Regularization과 Normalization\n","Regularization과 Normalization 이 두 개념은 서로 헷갈리는 경우가 많은 것 같습니다. 한국어로 번역할 때 두 개념이 다 '정규화'로 번역될 때가 많아서 더욱 혼란스러울 때가 많습니다. 우선 두 개념을 아래와 같이 정리해 보겠습니다."],"metadata":{"id":"KhSYU3NsKnY2"}},{"cell_type":"markdown","source":["## Regularization(정칙화)\n","---\n","정칙화라고 불리며, 오버피팅(overfitting)을 해결하기 위한 방법 중의 하나입니다. 오늘 우리가 가장 중요하게 다룰 주제이기도 하지요. **L1**, **L2 Regularization**, **Dropout**, **Batch normalization** 등이 있습니다. 오버피팅은 한국어로 과적합이라고 하며, train set은 매우 잘 맞히지만, validation/test set은 맞히지 못하는 현상을 말합니다. 비유하자면 오버피팅은 기출문제는 외워서 잘 맞히지만 새로운 응용 문제로 시험을 볼 때는 잘 풀지 못하는 경우라고 할 수 있겠습니다. 더 좋은 결과를 얻기 위해서는 새로운 시험, 즉 test set에서도 잘 맞혀야겠죠? 그래서 regularization 기법들은 모델에 제약 조건을 걸어서 모델의 train loss를 증가시키는 역할을 합니다. 그래서 train loss는 약간 증가하지만 결과적으로, validation loss나 최종 test loss를 감소시키려는 목적을 가지고 있지요."],"metadata":{"id":"HaGUnymFKnWu"}},{"cell_type":"markdown","source":["## Normalization(정규화)\n","---\n","**정규화**라고 불리며, 이는 데이터의 형태를 좀 더 의미 있게, 혹은 트레이닝에 적합하게 전처리하는 과정입니다. 데이터를 z-score로 바꾸거나 minmax scaler를 사용하여 0과 1사이의 값으로 분포를 조정하는 것들이 해당됩니다. 예를 들어, 금액과 같은 큰 범위의 값(10,000 ~ 10,000,000)과 시간(0~24)의 값이 들어가는 경우, 데이터의 분포가 피처(feature) 값의 범위에 의해 왜곡되어 학습에 방해가 된다는 문제가 있습니다. normalization은 모든 피처 값의 범위를 동일하게 하여 모델이 풀어야 하는 문제를 좀 더 간단하게 바꾸어 주는 전처리 과정입니다.\n","\n","이 두 가지 단어는 한국어로 번역 시에 혼용하여 쓰기도 하므로, 앞으로 이번 노드에서는 주로 영어로 표기하도록 하겠습니다. 핵심을 정리하면, regularization은 오버피팅을 막고자 하는 방법, normalization은 트레이닝을 할 때에 서로 범위가 다른 데이터들을 같은 범위로 바꿔주는 전처리 과정이라는 것입니다.\n","\n","Regularization와 Normalization의 간단한 예제를 [Iris dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-plants-dataset)의 회귀 문제를 풀면서 비교해 보겠습니다."],"metadata":{"id":"mIQqB8q-KnUO"}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","iris = load_iris()\n","iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n","target_df = pd.DataFrame(data=iris.target, columns=['species'])\n","\n","# 0, 1, 2로 되어있는 target 데이터를\n","# 알아보기 쉽게 'setosa', 'versicolor', 'virginica'로 바꿉니다\n","def converter(species):\n","    if species == 0:\n","        return 'setosa'\n","    elif species == 1:\n","        return 'versicolor'\n","    else:\n","        return 'virginica'\n","\n","target_df['species'] = target_df['species'].apply(converter)\n","\n","iris_df = pd.concat([iris_df, target_df], axis=1)\n","iris_df.head()"],"metadata":{"id":"ArJdWSRBLett"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Iris data 중 virginica라는 종의 petal length(꽃잎 길이)를 X, sepal length(꽃받침의 길이)를 Y로 두고 print 해보겠습니다."],"metadata":{"id":"C8tpMQXuKnR-"}},{"cell_type":"code","source":["X = [iris_df['petal length (cm)'][a] for a in iris_df.index if iris_df['species'][a]=='virginica']\n","Y = [iris_df['sepal length (cm)'][a] for a in iris_df.index if iris_df['species'][a]=='virginica']\n","\n","print(\"petal length(꽃잎 길이)\", X)\n","print(\"sepal length(꽃받침의 길이)\", Y)"],"metadata":{"id":"jQCRmI1ZLghO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["값으로만 보니 직관적으로 잘 와닿지 않네요! 산점도로 그려봅시다.\n","\n","아직 normalization을 하지 않았기 때문에 x축과 y축은 각각의 최솟값과 최댓값의 범위로 그려집니다."],"metadata":{"id":"NXcHxYN3KnOO"}},{"cell_type":"code","source":["plt.figure(figsize=(5,5))\n","plt.scatter(X,Y)\n","plt.title('petal-sepal scatter before normalization')\n","plt.xlabel('petal length (cm)')\n","plt.ylabel('sepal length (cm)')\n","plt.grid()\n","plt.show()"],"metadata":{"id":"ug6wY617Lki1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["그래프의 축을 잘 살펴보세요!\n","\n","이제 0-1로 normalization을 해주는 `minmax_scale`를 이용해서 산점도를 다시 한번 그려보겠습니다."],"metadata":{"id":"EMRwaOpWKnLW"}},{"cell_type":"code","source":["from sklearn.preprocessing import minmax_scale\n","\n","X_scale = minmax_scale(X)\n","Y_scale = minmax_scale(Y)\n","\n","plt.figure(figsize=(5,5))\n","plt.scatter(X_scale,Y_scale)\n","plt.title('petal-sepal scatter after normalization')\n","plt.xlabel('petal length (cm)')\n","plt.ylabel('sepal length (cm)')\n","plt.grid()\n","plt.show()"],"metadata":{"id":"3YXtK46-Lobd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["결과를 비교해 보면, 가장 큰 값을 1, 가장 작은 값을 0으로 하여 **축 범위가 바뀜**을 확인할 수 있습니다. 데이터의 상대적인 분포는 바뀌지 않았지만, 피처의 스케일이 0과 1 사이로 변환되었으므로 이후 X, Y의 관계를 다루기 용이해졌습니다.\n","\n","이번엔 같은 데이터로 간단한 회귀 문제를 풀면서 regularization에 대해 알아보겠습니다.\n","\n","`sklearn.linear_model`에 포함된 `LinearRegression` 모델을 사용하여 X-Y 관계를 선형으로 모델링해 보겠습니다. 이 `sklearn.linear_model`에는 L1, L2 regression인 `Lasso`와 `Ridge` 모델도 함께 포함되어 있으므로, 이들의 차이점을 먼저 직관적으로 이해해 보겠습니다. 수학적 정의나 보다 구체적인 설명은 다음 스텝에 이어집니다."],"metadata":{"id":"rthp4BRtKm92"}},{"cell_type":"code","source":["from sklearn.linear_model import LinearRegression\n","import numpy as np\n","\n","X = np.array(X)\n","Y = np.array(Y)\n","\n","# Iris Dataset을 Linear Regression으로 학습합니다.\n","linear= LinearRegression()\n","linear.fit(X.reshape(-1,1), Y)\n","\n","# Linear Regression의 기울기와 절편을 확인합니다.\n","a, b=linear.coef_, linear.intercept_\n","print(\"기울기 : %0.2f, 절편 : %0.2f\" %(a,b))"],"metadata":{"id":"IpBuOAzQLzeW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["위에서 linear regression으로 구한 기울기와 절편을 가지고 일차함수를 만들어 산점도와 함께 그려보겠습니다."],"metadata":{"id":"C5RnYH3NKm7m"}},{"cell_type":"code","source":["plt.figure(figsize=(5,5))\n","plt.scatter(X,Y)\n","plt.plot(X,linear.predict(X.reshape(-1,1)),'-b')\n","plt.title('petal-sepal scatter with linear regression')\n","plt.xlabel('petal length (cm)')\n","plt.ylabel('sepal length (cm)')\n","plt.grid()\n","plt.show()"],"metadata":{"id":"98I9IzfdL1zN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["이번에는 L1, L2 regularization으로 regression을 해보겠습니다. 이는 `Lasso`, `Ridge`라고 부릅니다.\n","\n","먼저 L1 regularization인 `Lasso`로 문제를 풀어보겠습니다."],"metadata":{"id":"Jz4cnLfDKm5W"}},{"cell_type":"code","source":["# Q. linear regression의 코드를 참고하여, 아래 코드를 채워주세요!\n","\n","# L1 regularization은 Lasso로 import 합니다.\n","from sklearn.linear_model import Lasso\n","\n","L1 = Lasso()\n","# [[YOUR CODE]]\n","a, b = # [[YOUR CODE]]\n","print(\"기울기 : %0.2f, 절편 : %0.2f\" %(a,b))\n","\n","plt.figure(figsize=(5,5))\n","# [[YOUR CODE]]\n","plt.title('petal-sepal scatter with L1 regularization(Lasso)')\n","plt.xlabel('petal length (cm)')\n","plt.ylabel('sepal length (cm)')\n","plt.grid()\n","plt.show()"],"metadata":{"id":"nwUkJIZTL7ZN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["어떤가요? 혹시 기울기가 0으로 나오지 않았나요? `Lasso` 방법은 결과가 별로 좋지 않은 것 같습니다.\n","\n","이제 같은 데이터셋으로 L2 regularization인 `Ridge`로 문제를 풀어보고 서로 비교해 보겠습니다."],"metadata":{"id":"neS8MtZgKm29"}},{"cell_type":"code","source":["# Q. linear regression의 코드를 참고하여, 아래 코드를 채워주세요!\n","\n","# L2 regularization은 Ridge로 import 합니다.\n","from sklearn.linear_model import Ridge\n","\n","L2 = Ridge()\n","# [[YOUR CODE]]\n","a, b = # [[YOUR CODE]]\n","print(\"기울기 : %0.2f, 절편 : %0.2f\" %(a,b))\n","\n","plt.figure(figsize=(5,5))\n","# [[YOUR CODE]]\n","plt.title('petal-sepal scatter with L2 regularization(Ridge)')\n","plt.xlabel('petal length (cm)')\n","plt.ylabel('sepal length (cm)')\n","plt.grid()\n","plt.show()"],"metadata":{"id":"6pM_M_njMAAO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["다시 다루겠지만, linear regression이 L2 norm과 관련이 있습니다. 그래서 L2 regularization을 쓰는 `Ridge`방법으로는 앞서 linear regression과 큰 차이가 없는 결과가 나옵니다.\n","그러나 왜 L1 regularization을 쓰는 `Lasso`에서는 이상한 결과가 나왔을까요?\n","\n","다음 스텝에서 그 이유를 알아보도록 하겠습니다!"],"metadata":{"id":"ii1Y1RrlKm02"}},{"cell_type":"markdown","source":["# L1 Regularization\n","이전 스텝에서 regularization과 normalization의 정의를 설명하고, L1/L2 regularization을 코드로 맛보기 해보았습니다. 마지막에 같은 linear regression 문제를 푸는데 L1 regularization에서는 문제가 풀리지 않았다는 것을 기억하시나요?\n","\n","L1 regularization을 설명하면서, 지난 스텝에서 `Lasso`로는 regression 문제가 제대로 풀리지 않았던 현상을 더 자세히 알아보겠습니다. 그리고 어떤 때에 L1 regularization을 사용하는지 알아보는 것이 목표입니다!"],"metadata":{"id":"zkinfJURKmyv"}},{"cell_type":"markdown","source":["## L1 regularization (Lasso)의 정의\n","---\n","L1 regularization은 아래와 같은 식으로 정의됩니다. ($\\text{N}$: 데이터의 개수, $\\text{D}$: 데이터의 차원(feature의 개수))\n","$$\\hat{\\beta ^{\\text{lasso}}}:=\\text{argmin}_{\\beta}\\frac{1}{2N}\\sum _{i=1}^{N}(y_{i}-\\beta_{0}-\\sum _{j=1}^D\\textbf{x}_{ij}\\beta _{j})^2+\\lambda \\sum _{j=1}^{D}\\left | \\beta _{j}\\right |$$\n","\n","여기서 중요하게 봐야 할 부분은 $\\lambda \\sum _{j=1}^{D}\\left | \\beta _{j}\\right |$입니다. 이 부분이 없다면 linear regression과 동일합니다.\n","\n","이 부분이 바로 L1 norm에 해당하는 부분인데, L1 regularization이라는 이름이 붙은 이유이기도 하고, L2 regularization과의 차이가 나타나는 중요한 부분입니다.\n","\n",">💡참고 지식 (Lp norm)\n",">\n",">norm은 벡터나 행렬, 함수 등의 거리를 나타내는 것으로 우리는 여기서 벡터값만 다룰 예정입니다. Lp norm 의 정의는 아래와 같습니다. (참고) [Norm (mathematics)](https://en.wikipedia.org/wiki/Norm_(mathematics))\n","\n","$$\\left\\| \\textbf{x}\\right\\|_{P}:=(\\sum _{i=1}^{n}\\left | \\textbf{x}_{i}\\right |^{P})^{\\frac{1}{P}}$$\n","\n","norm에 대해서는 이후 스텝에서 더 자세히 다룰 예정입니다!\n","\n","그렇다면 $P=1$인 경우의 L1 norm은 $\\left\\| \\textbf{x}\\right\\|_{1}=\\sum _{i=1}^{n}\\left | \\textbf{x}_{i}\\right |$\n","로 나타낼 수 있습니다.\n","\n","이는 위에서 봤던 $\\lambda \\sum _{j=1}^{D}\\left | \\beta _{j}\\right |$에 들어가 있는 수식과 일치합니다!\n","\n","때문에 $P=1$이므로 L1 regularization이라고 부르는 것입니다.\n","하지만 사이킷런이나 케라스, 텐서플로우 등의 패키지에서는 `Lasso` 라는 이름을 더 자주 사용합니다. 그럼 저번 시간에 사용해 본 코드의 일부분을 살펴볼까요?"],"metadata":{"id":"ViqkuKk9Kmwe"}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","iris = load_iris()\n","iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n","target_df = pd.DataFrame(data=iris.target, columns=['species'])\n","\n","def converter(species):\n","    if species == 0:\n","        return 'setosa'\n","    elif species == 1:\n","        return 'versicolor'\n","    else:\n","        return 'virginica'\n","\n","target_df['species'] = target_df['species'].apply(converter)\n","\n","iris_df = pd.concat([iris_df, target_df], axis=1)\n","iris_df.head()"],"metadata":{"id":"epVCe7AHP8S-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = [iris_df['petal length (cm)'][a] for a in iris_df.index if iris_df['species'][a]=='virginica']\n","Y = [iris_df['sepal length (cm)'][a] for a in iris_df.index if iris_df['species'][a]=='virginica']\n","\n","X = np.array(X)\n","Y = np.array(Y)\n","\n","plt.figure(figsize=(5,5))\n","plt.scatter(X,Y)\n","plt.xlabel('petal length (cm)')\n","plt.ylabel('sepal length (cm)')\n","plt.grid()\n","plt.show()"],"metadata":{"id":"6r_aghilP989"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import Lasso\n","\n","L1 = Lasso()\n","L1.fit(X.reshape(-1,1), Y)\n","a, b = L1.coef_, L1.intercept_\n","print(\"기울기 : %0.2f, 절편 : %0.2f\" %(a,b))\n","\n","plt.figure(figsize=(5,5))\n","plt.scatter(X,Y)\n","plt.plot(X,L1.predict(X.reshape(-1,1)),'-b')\n","plt.xlabel('petal length (cm)')\n","plt.ylabel('sepal length (cm)')\n","plt.grid()\n","plt.show()"],"metadata":{"id":"iT1fyAi1P-5u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["흠... 기울기가 0으로 나오는 것이 아무래도 이상한데요...🤔\n","아무래도 데이터의 feature 개수가 2개밖에 되지 않으니까 이게 맞는 건지 아직 잘 모르겠습니다. 일단 다른 데이터셋으로 L1 regularization을 한번 더 돌려보겠습니다."],"metadata":{"id":"-O-i87tUKmuO"}},{"cell_type":"markdown","source":["## 컬럼 수가 많은 데이터에서의 L1 regularization 비교\n","---\n","Iris 데이터는 특성이 총 4개로 컬럼 수가 너무 적으니 [wine dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html)을 이용해 보겠습니다.\n","총 13개의 특성을 갖는 데이터입니다."],"metadata":{"id":"fZU_rE3zKmsO"}},{"cell_type":"code","source":["from sklearn.datasets import load_wine\n","\n","wine = load_wine()\n","wine_df = pd.DataFrame(data=wine.data, columns=wine.feature_names)\n","target_df = pd.DataFrame(data=wine.target, columns=['Y'])"],"metadata":{"id":"c_BNpn2yQGot"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["잠깐 데이터셋의 예시를 살펴볼까요?"],"metadata":{"id":"mZtCAY2pKmpW"}},{"cell_type":"code","source":["wine_df.head(5)"],"metadata":{"id":"gm1bEiAvQHvt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_df.head(5)"],"metadata":{"id":"pvf51TKHQJlt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["먼저 linear regression 으로 문제를 풀고, 그 계수(coefficient)와 절대 오차(mean absolute error), 제곱 오차(mean squared error), 평균 제곱값 오차(root mean squared error)를 출력해 보겠습니다."],"metadata":{"id":"9WUcRYtmKmmu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wx1nWD_rKaAl"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","\n","# 데이터를 준비하고\n","X_train, X_test, y_train, y_test = train_test_split(wine_df, target_df, test_size=0.3, random_state=101)\n","\n","# 모델을 훈련시킵니다.\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","\n","# 테스트를 해볼까요?\n","pred = model.predict(X_test)\n","\n","# 테스트 결과는 이렇습니다!\n","print(\"result of linear regression\")\n","print('Mean Absolute Error:', mean_absolute_error(y_test, pred))\n","print('Mean Squared Error:', mean_squared_error(y_test, pred))\n","print('Mean Root Squared Error:', np.sqrt(mean_squared_error(y_test, pred)))\n","\n","print(\"\\n\\n coefficient linear regression\")\n","print(model.coef_)"]},{"cell_type":"markdown","source":["이번에는 L1 regularization으로 문제를 풀어보겠습니다."],"metadata":{"id":"6625f71vQOsV"}},{"cell_type":"code","source":["# Q. 위의 Iris 예제 코드를 참고해서, 빈칸을 채워봅시다.\n","\n","from sklearn.linear_model import Lasso\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","\n","# 모델을 준비하고 훈련시킵니다.\n","L1 = Lasso(alpha=0.05)\n","# [[YOUR CODE]]\n","\n","# 테스트를 해봅시다.\n","pred = # [[YOUR CODE]]\n","\n","# 모델 성능은 얼마나 좋을까요?\n","print(\"Result of Lasso\")\n","print('Mean Absolute Error:', # [[YOUR CODE]])\n","print('Mean Squared Error:', # [[YOUR CODE]])\n","print('Mean Root Squared Error:', # [[YOUR CODE]])\n","\n","print(\"\\n\\n coefficient of Lasso\")\n","print(# [[YOUR CODE]])"],"metadata":{"id":"Xn0oEzEEQPT9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 결과 분석\n","---\n","coefficient 부분을 보시면 linear regression과 L1 regularization의 차이가 좀 더 두드러짐을 알 수 있습니다. linear regression에서는 모든 컬럼의 가중치가 0이 아닌 값을 가지고 있지만, L1 regularization에서는 총 13개 중 7개를 제외한 나머지의 값들이 모두 0임을 확인할 수 있습니다. error 부분에서는 큰 차이가 없었지만, 우리가 어떤 컬럼이 결과에 영향을 더 크게 미치는지 확실히 확인할 수 있습니다. 이러한 경우 다른 문제에서도 error의 차이가 크게 나지 않는다면, 차원 축소와 비슷한 개념으로 변수의 값을 7개만 남겨도 충분히 결과를 예측할 수 있습니다. 다만 linear regression과 L1, L2 regularization의 차이 중 하나는 하이퍼파라미터(수식에서는 $\\lambda$)가 하나 더 들어간다는 것이고, 그 값에 따라 error에 영향을 미친다는 점입니다."],"metadata":{"id":"59eLJGrhQOoe"}},{"cell_type":"markdown","source":["# L2 Regularization"],"metadata":{"id":"bqvVHkeuQOmQ"}},{"cell_type":"markdown","source":["## L2 Regularization(Ridge)의 정의\n","---\n","L2 regularization은 아래와 같은 식으로 정의됩니다.\n","$$\\hat{\\beta ^{\\text{ridge}}}:=\\text{argmin}_{\\beta}\\frac{1}{2N}\\sum _{i=1}^{N}(y_{i}-\\beta_{0}-\\sum _{j=1}^D\\textbf{x}_{ij}\\beta _j)^{2}+\\lambda \\sum _{j=1}^{D}\\beta _{j}^{2}$$\n","아래는 L1 regularization의 정의입니다.\n","$$\\hat{\\beta ^{\\text{lasso}}}:=\\text{argmin}_{\\beta}\\frac{1}{2N}\\sum _{i=1}^{N}(y_{i}-\\beta_{0}-\\sum _{j=1}^D\\textbf{x}_{ij}\\beta _j)^{2}+\\lambda \\sum _{j=1}^{D}\\left | \\beta _{j} \\right |$$\n","자 이제 두 regularization 수식의 차이가 어디에 있는지 보이시나요? 이전 스텝에서 잠깐 Lp norm을 설명드렸는데, 그것이 L1 / L2 regularization의 이름과 큰 관련이 있다고 하였습니다. L2 regularization에서는 $\\lambda \\sum _{j=1}^{D}\\beta _{j}^{2}$ 부분이 핵심 내용이 됩니다.\n","\n","$\\sum _{j=1}^{D}\\beta _{j}^{2}$ &larr; 이 부분이 이전 스텝에서 설명드린 L2 Norm의 형태와 똑같음을 확인할 수 있습니다."],"metadata":{"id":"whfflHlxQOkO"}},{"cell_type":"markdown","source":["## L1 / L2 Regularization의 차이점\n","---\n","L1 regularization이 L2 regularization과 다르게 **왜 일부 컬럼의 가중치를 0으로 보내는지** 증명하는 내용은 이 노드의 범위를 벗어나기 때문에, 대략적으로만 설명해 보겠습니다."],"metadata":{"id":"8z7vn6O0QOh-"}},{"cell_type":"markdown","source":["![image.png](data:image/png;base64,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)\n","[https://en.wikipedia.org/wiki/Lasso_(statistics)]"],"metadata":{"id":"3eggwfYCSbpN"}},{"cell_type":"markdown","source":["위 그림에서, L1 regularization(왼쪽)은 $\\left | \\text{w}_{1} \\right | + \\left | \\text{w}_{2} \\right |$의 값을 최소화하는 것이 목적이므로 마름모 형태의 제약 조건이 생깁니다. 그리고 빨간색 직선은 우리가 풀어야 하는 문제의 해답이 될 수 있는 파라미터($\\text{w}_{1}$, $\\text{w}_{2}$)들의 집합입니다. 마름모의 크기를 점점 늘렸을 때 ($\\left | \\text{w}_{1} \\right | + \\left | \\text{w}_{2} \\right |$의 값을 증가시켰을 때), 이 직선('정답 파라미터 집합')이 마름모와 만나는 지점이 바로 $\\left | \\text{w}_{1} \\right | + \\left | \\text{w}_{2} \\right |$의 값을 최소화하는 해가 됩니다. L1 regularization은 제약 조건이 꼭지점이 각 축 위에 있는 마름모 모양이기 때문에, '정답 파라미터 집합'과 만나는 지점 역시 축 위에 있을 가능성이 높습니다. 좌표계에서 어떤 점이 축 위에 있다면 몇 개의 좌표는 0 값을 가지게 되죠. 그래서 L1 regularization의 결과를 보면 모델의 일부 coefficient 값이 0으로 나오는 것을 확인할 수 있습니다. 이전 스텝의 Iris dataset 예제에서는 기울기 값이 0으로 나왔고, wine dataset 예제에서도 몇 개의 coefficient가 0으로 바뀌었습니다.\n","\n","이와 다르게 L2 regularization은 $\\text{w}_{1}^{2} + \\text{w}_{2}^{2}$값을 최소화하므로 제약 조건이 원의 형태로 나타나게 됩니다. 그러므로 직선과 만나는 지점이 축 위에 있을 가능성보다, 축과 가까운 다른 곳에 있을 가능성이 높습니다. wine dataset 예제에서도 L2 regularization 결과에서는 coefficient가 모두 0이 아닌 값을 가지고 있었죠. 또한 제곱이 들어가 있기 때문에 절댓값으로 L1 norm을 쓰는 Lasso보다는 수렴이 빠르다는 장점이 있습니다. 이는 이전과 같은 문제에서 iteration 조건을 추가하여 실험해보겠습니다.\n","\n","바로 직관적으로 이해하기 쉽지 않죠? 조금 더 직관적으로 이해하고 싶다면 아래 블로그를 참고해주세요\n","\n","- [정규화에 대해 자세하게 알아보자!](https://modulabs.co.kr/blog/learn-about-regularization)"],"metadata":{"id":"UGgWsXdHQOfl"}},{"cell_type":"code","source":["from sklearn.datasets import load_wine\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","\n","wine = load_wine()\n","wine_df = pd.DataFrame(data=wine.data, columns=wine.feature_names)\n","target_df = pd.DataFrame(data=wine.target, columns=['Y'])\n","X_train, X_test, y_train, y_test = train_test_split(wine_df, target_df, test_size= 0.3, random_state=101)\n","print('=3')"],"metadata":{"id":"WSHi9zFGTlql"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["L1 regularization으로 iteration 횟수를 5회로 두고 문제를 풀어보겠습니다."],"metadata":{"id":"pjZT1jKcQOde"}},{"cell_type":"code","source":["%%time\n","from sklearn.linear_model import Lasso\n","\n","L1 = Lasso(alpha=0.05, max_iter=5)\n","L1.fit(X_train, y_train)\n","pred = L1.predict(X_test)\n","\n","print(\"result of Lasso\")\n","print('Mean Absolute Error:', mean_absolute_error(y_test, pred))\n","print('Mean Squared Error:', mean_squared_error(y_test, pred))\n","print('Mean Root Squared Error:', np.sqrt(mean_squared_error(y_test, pred)))\n","\n","print(\"\\n\\n coefficient of Lasso\")\n","print(L1.coef_)"],"metadata":{"id":"cDK-JtGBTpvN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["L2 regularization도 같은 제약조건을 두고 문제를 풀어보겠습니다."],"metadata":{"id":"3PcF6hNRQOZF"}},{"cell_type":"code","source":["# Q. L1 regularization 코드를 참고하여 아래 코드를 채워주세요.\n","%%time\n","from sklearn.linear_model import Ridge\n","\n","# [[YOUR CODE]]\n","\n","print(\"result of Ridge\")\n","print('Mean Absolute Error:', mean_absolute_error(y_test, pred))\n","print('Mean Squared Error:', mean_squared_error(y_test, pred))\n","print('Mean Root Squared Error:', np.sqrt(mean_squared_error(y_test, pred)))\n","\n","print(\"\\n\\n coefficient of Ridge\")\n","print(L2.coef_)"],"metadata":{"id":"s_WEyHSuTsPN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["iteration 값을 5로만 설정해 보아도, L2 regularization의 결과는 linear regression과 같은 값이 나오지만, L1 regularization에서는 앞 step과 같은 값을 확인할 수는 없었습니다. 심지어 수렴하지 않았다는 경고까지 나오는군요! 이는 아직 다른 조건들을 만족하는 답을 찾지 못하였다는 뜻입니다.\n","\n","정리하면, L1 regularization은 가중치가 적은 벡터에 해당하는 계수를 0으로 보내면서 **차원 축소와 비슷한 역할**을 하는 것이 특징이며, L2 regularization은 계수를 0으로 보내지는 않지만 제곱 텀이 있기 때문에 L1 regularization보다는 **수렴 속도가 빠르다**는 장점이 있습니다. 예를 들어, $\\text{A}=\\begin{bmatrix} 1,1,1,1,1 \\end{bmatrix}$, $\\text{B}=\\begin{bmatrix} 5, 0, 0, 0, 0 \\end{bmatrix}$ 의 경우 L1-norm은 같지만, L2-norm은 같지 않습니다. 즉, 제곱 텀에서 결과에 큰 영향을 미치는 값은 더 크게, 결과에 영향이 적은 값들은 더 작게 보내면서 수렴 속도가 빨라지는 것입니다.\n","\n","그러므로, 데이터에 따라 적절한 regularization 방법을 활용하는 것이 좋습니다."],"metadata":{"id":"DLdVCGDcQOW9"}},{"cell_type":"markdown","source":["# Extra : Lp norm\n","이전 스텝에서 잠깐 소개해드린 Lp norm에 대해 자세히 설명하겠습니다.\n","**Norm**이라는 용어는 벡터뿐만 아니라 함수, 행렬의 크기를 나타내는 개념으로, 딥러닝을 배우는 과정에서는 주로 벡터, 좀 더 어렵게는 행렬의 norm 정도만 알면 됩니다."],"metadata":{"id":"POqNB62fQOUm"}},{"cell_type":"markdown","source":["## Vector norm\n","---\n","L1 / L2 regularization에서 배운 norm은 벡터에서 정의된 norm으로 아래와 같습니다.\n","$$\\left\\| \\text{x} \\right\\|_{P}:=(\\sum _{i=1}^{n} \\text{x}_{i}^{P})^{\\frac{1}{P}}$$\n","아래 코드에서 P의 값과 X의 형태를 바꾸어가며 실험해 보세요."],"metadata":{"id":"n-7U5clwQOSH"}},{"cell_type":"code","source":["# [Playground] x와 p를 바꾸어가며 norm 값이 어떻게 변하는지 실험해봅시다!\n","# --------------------------- #\n","x = np.array([1,10,1,1,1])\n","p = 5\n","# --------------------------- #\n","\n","norm_x = np.linalg.norm(x, ord=p)\n","making_norm = (sum(x**p))**(1/p)\n","print(\"result of numpy package norm function : %0.5f \"%norm_x)\n","print(\"result of making norm : %0.5f \"%making_norm)"],"metadata":{"id":"0ZhwWWvXVNGN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["그러면, 이제 P가 우리가 생각하는 자연수가 아닌 경우에는 어떻게 될까요?\n","\n","$P=\\infty$인 infinity norm의 경우는 x에서 가장 큰 숫자를 출력합니다.\n","\n","$$\\left\\| \\text{x} \\right\\|_{P}:= \\max (\\text{x})$$"],"metadata":{"id":"T383-BlMQOPu"}},{"cell_type":"code","source":["norm_x = np.linalg.norm(x, ord=np.inf)\n","print(\"result of infinite norm : %0.5f \"%norm_x)"],"metadata":{"id":"K_ukTStXVsd1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Matrix norm\n","---\n","행렬의 norm의 경우는 벡터와 조금 다르며, 주로 $P=1, \\infty$인 경우만 알면 됩니다.\n","\n","현재 A는 $\\text{m} \\times \\text{n}$ 행렬입니다.\n","\n","$$\\left\\| \\text{A} \\right\\|_{1}= \\max_{1\\leq j\\leq n}\\sum _{i=1}^{m}\\left | \\textbf{a} _{ij} \\right |$$\n","\n","$$\\left\\| \\text{A} \\right\\|_{\\infty }= \\max_{1\\leq j\\leq m}\\sum _{i=1}^{n}\\left | \\textbf{a} _{ij} \\right |$$\n","\n","$P=1$인 경우에는 컬럼(column)의 합이 가장 큰 값이 출력되고. $P=\\infty$인 경우에는 로우(row)의 합이 가장 큰 값이 출력됩니다."],"metadata":{"id":"W1a0aaFJQOLt"}},{"cell_type":"code","source":["A = np.array([[1,2,3], [1,2,3], [4,6,8]])\n","\n","one_norm_A = np.linalg.norm(A, ord=1)\n","print(\"result one norm of A :\", one_norm_A)\n","\n","inf_norm_A = np.linalg.norm(A, ord=np.inf)\n","print(\"result inf norm of A :\", inf_norm_A)"],"metadata":{"id":"KN9b3wSUXXdl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dropout\n","드롭아웃(Dropout) 기법은 2014년도에 나온 논문입니다.\n","\n","**논문 제목** : Dropout: A Simple Way to Prevent Neural Networks from Overfitting  \n","**논문 발표 시점** : 2014년  \n","**논문 링크** : [논문 주소](https://jmlr.org/papers/v15/srivastava14a.html)\n","\n","드롭아웃 기법이 나오기 전의 신경망은 fully connected architecture로 모든 뉴런들이 연결되어 있었습니다.\n","\n","드롭아웃이란 확률적으로 랜덤하게 몇 가지의 뉴런만 선택하여 정보를 전달하는 과정입니다. 이름 그대로 몇 가지의 값들을 모든 뉴런에 전달하는 것이 아닌, 확률적으로 버리면서 전달하는 기법입니다. 드롭아웃은 오버피팅을 막는 regularization layer 중 하나입니다. 확률을 너무 높이면 (비활성화된 뉴런의 비중을 높이면) 모델 안에서 값들이 제대로 전달되지 않으므로 학습이 잘 되지 않고, 확률을 너무 낮추는 경우에는 fully connected layer와 같이 동작합니다. fully connected layer에서 오버피팅이 생기는 경우에 주로 dropout layer를 추가합니다.\n","\n","코드는 간단합니다. 논문이 나온 지도 오래되었기 때문에, 여러 프레임워크에서 간단하게 구현할 수 있도록 되어있습니다.\n","\n","- [Pytorch Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)"],"metadata":{"id":"VnzzauruQOHt"}},{"cell_type":"markdown","source":["## 실습 (not overfitting)\n","---\n","[fashion mnist](https://keras.io/api/datasets/fashion_mnist/)라는 데이터 셋을 불러와서 학습을 시키도록 하겠습니다. 이 데이터셋은 총 10개의 클래스로 구성되어 있고, 데이터가 간단한 편이기도 하여 5 epoch 정도만 학습시켜도 어느 정도 결과가 나옵니다. 드롭아웃 레이어를 중간에 추가하여 확률을 1에 가깝게 주면 어떻게 되는지 살펴보도록 하겠습니다."],"metadata":{"id":"hCSyibn7QOEd"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torch.utils.data import DataLoader, random_split\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print('=3')"],"metadata":{"id":"YPT8inIH52VL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n","               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)"],"metadata":{"id":"LafWlzSf6N1j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"],"metadata":{"id":"lZUpXaEC6eCr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["dropout의 확률을 0.9로 주었을 때의 결과를 살펴보도록 하겠습니다."],"metadata":{"id":"Ckxgd4nlQOBF"}},{"cell_type":"code","source":["class ClassifierModel(nn.Module):\n","    def __init__(self, dropout_rate):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(28*28, 128)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.fc2 = nn.Linear(128, 10)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        return x"],"metadata":{"id":"lOuEGOI76g5K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, train_loader, criterion, optimizer, epochs=5):\n","    model.train()\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","        for images, labels in train_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += labels.size(0)\n","            correct += predicted.eq(labels).sum().item()\n","\n","        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n"],"metadata":{"id":"KOnhx15U6uBi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","model_with_dropout = ClassifierModel(dropout_rate=0.9).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model_with_dropout.parameters(), lr=0.001)\n","\n","train(model_with_dropout, train_loader, criterion, optimizer, epochs=5)"],"metadata":{"id":"Z7qGOucj6vFL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["dropout이 없을 때 실습을 해보면, 5 epoch 정도만 돌려도 충분히 높은 정확도를 볼 수 있습니다."],"metadata":{"id":"rFmKoBM7XvFU"}},{"cell_type":"code","source":["%%time\n","model_without_dropout = ClassifierModel(dropout_rate=0).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model_without_dropout.parameters(), lr=0.001)\n","\n","train(model_without_dropout, train_loader, criterion, optimizer, epochs=5)"],"metadata":{"id":"gsb35g9-NAL0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["현재 이 데이터 셋은 학습이 잘 되는 데이터 셋으로, fully connected layer에서도 결과가 잘 나옴을 확인할 수 있는데요. 일부러 중간에 dropout layer를 추가하여 0.9의 확률 값을 주니 학습이 안 됨을 확인하였습니다. 다음은 overfitting이 나는 환경에서 dropout의 중요성을 알아보도록 하겠습니다."],"metadata":{"id":"NnxTgly4XxEc"}},{"cell_type":"markdown","source":["## 실습 (overfitting)\n","---\n","overfitting이 되는지 확인해 보려면 train set과 validation set의 loss function을 그려보는 것이 가장 첫 번째 시도입니다. 우리는 위의 데이터를 이제 train:valid=99:1의 비율로 나눈 뒤에 loss function의 값을 그려보고, overfitting이 생기는 fully connected layer를 만들어보도록 합시다. overfitting이 되게 하기 위해 의도적으로 train set을 99%로 늘리고 validation set을 줄였습니다.\n","\n",">📖 학습팁\n",">\n",">아래 코드는 200 epoch이므로 코드가 돌아가는데 5분이상 소요됩니다. 그동안 overfitting에 대한 자료를 찾아보면서 기다려주세요!"],"metadata":{"id":"2IoJZA4VXx1U"}},{"cell_type":"code","source":["train_size = int(0.99 * len(train_dataset))\n","valid_size = len(train_dataset) - train_size\n","train_data, valid_data = random_split(train_dataset, [train_size, valid_size])\n","\n","train_loader = DataLoader(train_data, batch_size=512, shuffle=True)\n","valid_loader = DataLoader(valid_data, batch_size=512, shuffle=False)"],"metadata":{"id":"iOiaVg1PNJU7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class OverfitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(28*28, 256)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(256, 10)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        return x"],"metadata":{"id":"GcF4VNtz7shJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, train_loader, valid_loader, criterion, optimizer, epochs=200):\n","    train_loss, valid_loss, train_acc, valid_acc = [], [], [], []\n","    model.train()\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        correct_train, total_train = 0, 0\n","        for images, labels in train_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total_train += labels.size(0)\n","            correct_train += predicted.eq(labels).sum().item()\n","        train_loss.append(total_loss / len(train_loader))\n","        train_acc.append(100 * correct_train / total_train)\n","\n","        model.eval()\n","        temp_loss, correct_valid, total_valid = 0, 0, 0\n","        with torch.no_grad():\n","            for images, labels in valid_loader:\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","                temp_loss += loss.item()\n","                _, predicted = outputs.max(1)\n","                total_valid += labels.size(0)\n","                correct_valid += predicted.eq(labels).sum().item()\n","        valid_loss.append(temp_loss / len(valid_loader))\n","        valid_acc.append(100 * correct_valid / total_valid)\n","        model.train()\n","\n","        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss[-1]:.4f}, Valid Loss: {valid_loss[-1]:.4f}, Train Acc: {train_acc[-1]:.2f}%, Valid Acc: {valid_acc[-1]:.2f}%\")\n","    return train_loss, valid_loss, train_acc, valid_acc"],"metadata":{"id":"qEBTdy4Y7tQJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","# Dropout이 없는 모델 학습\n","model_overfit = OverfitModel().to(device)\n","optimizer = optim.Adam(model_overfit.parameters(), lr=0.001)\n","train_loss, valid_loss, train_acc, valid_acc = train(model_overfit, train_loader, valid_loader, criterion, optimizer)"],"metadata":{"id":"b7CfhSB47zQx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loss 값을 plot 해보겠습니다.\n","plt.plot(train_loss, label='Train Loss', color='blue')\n","plt.plot(valid_loss, label='Validation Loss', color='red')\n","plt.legend()\n","plt.title('Loss Graph without Dropout')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.grid()\n","plt.show()"],"metadata":{"id":"Fwyrhc1o9zGB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# accuracy 값을 plot 해보겠습니다.\n","plt.plot(train_acc, label='Train Accuracy', color='blue')\n","plt.plot(valid_acc, label='Validation Accuracy', color='red')\n","plt.legend()\n","plt.title('Accuracy Graph without Dropout')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.grid()\n","plt.show()"],"metadata":{"id":"eZsi6zsf-W9B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["dropout layer가 없는 fully connected layer에서 200번 정도의 학습을 하니 train set의 accuracy는 올라가고, loss는 점점 떨어졌습니다. 그러나 validation set의 accuracy와 loss는 어느 정도 값에서 수렴함을 볼 수 있었습니다.\n","이렇게 오버피팅을 만든 환경에서 dropout layer를 추가한 뒤 나머지 환경은 같게 한 실험을 살펴보도록 하겠습니다."],"metadata":{"id":"mjH1Kr0nXysE"}},{"cell_type":"code","source":["# Q. dropout layer를 추가해보세요. (dropout 확률은 0.5로 지정해주세요.)\n","class DropModel(nn.Module):\n","    def __init__(self, dropout_rate):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(28*28, 256)\n","        self.relu = nn.ReLU()\n","        # 여기에 dropout layer를 추가해보았습니다. 나머지 layer는 위의 실습과 같습니다.\n","        # [[YOUR CODE]]\n","        self.fc2 = nn.Linear(256, 10)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        # 여기에 dropout layer를 추가해보았습니다. 나머지 layer는 위의 실습과 같습니다.\n","        # [[YOUR CODE]]\n","        x = self.fc2(x)\n","        return x"],"metadata":{"id":"eZ5m0IaC-bk5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","model_dropout = DropModel(dropout_rate=# [[YOUR CODE]]).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model_dropout.parameters(), lr=0.001)\n","train_loss, valid_loss, train_acc, valid_acc = train(model_dropout, train_loader, valid_loader, criterion, optimizer)"],"metadata":{"id":"zSb4IdnS-zWJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Q. loss 값의 그래프를 그려봅시다.\n","plt.plot(# [[YOUR CODE]], label='Train Loss', color='blue')\n","plt.plot(# [[YOUR CODE]], label='Validation Loss', color='red')\n","plt.legend()\n","plt.title('Loss Graph without Dropout')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.grid()\n","plt.show()"],"metadata":{"id":"j7wRs_6O_E8q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Q. accuracy 값의 그래프를 그려봅시다.\n","plt.plot(# [[YOUR CODE]], label='Train Accuracy', color='blue')\n","plt.plot(# [[YOUR CODE]], label='Validation Accuracy', color='red')\n","plt.legend()\n","plt.title('Accuracy Graph without Dropout')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.grid()\n","plt.show()"],"metadata":{"id":"Z1SgrK6S_E2R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["좋은 데이터를 가지고 오버피팅을 만드는 환경이 조금 어렵긴 했지만, dropout layer 하나만으로도 오버피팅을 막고, 두 데이터 셋이 정확도도 비슷하게 나옴을 확인하였습니다. 사실 더 복잡한 네트워크나, 더 어려운 데이터의 경우에는 이러한 오버피팅이 더 자주 있는 일이므로, dropout layer를 추가하는 경우가 많습니다. 하지만 이 또한 확률 값이 파라미터로 들어가므로, 어떠한 값을 선택하느냐는 데이터와 네트워크에 따라 달린 일입니다."],"metadata":{"id":"P4PjVCC5Xypl"}},{"cell_type":"markdown","source":["# Batch Normalization\n","**논문 제목** : Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift \\\n","**논문 발표 시점** : 2015년 \\\n","**논문 링크** : [논문 PDF](https://arxiv.org/pdf/1502.03167.pdf)  \n","*(batch normalization과 internal covariate shift가 연관성이 없다는 [반론](https://arxiv.org/pdf/1805.11604.pdf)도 있기 때문에, \"이런 이야기도 있구나~\" 하고 받아들이시면 됩니다.)*\n","\n","딥러닝에서 경사 하강법(gradient descent)으로 모델의 가중치를 업데이트할 때, 데이터셋 전체를 본 다음 업데이트하는 'Batch Gradient Descent'와 데이터 하나를 관찰할 때마다 업데이트하는 'Stochastic Gradient Descent' 방법이 있었죠. 이 둘의 절충안이 바로 데이터셋을 여러 개의 **mini-batch**로 쪼갠 다음 하나의 batch를 처리할 때마다 가중치를 업데이트하는 'Mini-batch Gradient Descent'입니다. 데이터셋을 mini-batch로 쪼개는 방법은 학습 속도와 안정성 모두를 잡았지만, 딥러닝 모델 안에서 데이터가 처리되면서 여러 개의 mini-batch들 사이에 데이터 분포의 차이가 생길 수 있다는 문제가 있었습니다. (이것이 internal covariate shift를 대략적으로 설명한 부분입니다.)\n","\n","데이터 분포의 차이가 존재한다면 gradient 값의 차이도 있을 것이고, 같은 learning rate 값을 가지고 있더라도 gradient vanishing이나 gradient explode 문제가 생길 수 있습니다. batch normalization 기법은 각 mini-batch마다 평균과 분산을 계산하여 정규화(normalization)를 수행하고, `scale and shift` 변환을 적용하여 mini-batch들이 비슷한 데이터 분포를 가지도록 합니다.\n","\n","논문에서 설명한 알고리즘을 아래에 적어보도록 하겠습니다.\n","\n","**Input**: Values of x over a mini-batch: $\\text{B}=\\begin{Bmatrix}\\textbf{x}_{1} & \\cdots & \\textbf{x}_{m} \\\\ \\end{Bmatrix}$ Parameters to be learned: $\\gamma$, $\\beta$\n","\n","**Output**: $\\begin{Bmatrix} y_{i}=\\text{BN}_{\\gamma, \\beta}(\\textbf{x}_{i}) \\end{Bmatrix}$\n","\n","1. mini-batch mean :\n","$$\\mu_{B} \\leftarrow \\frac{1}{m}\\sum _{i=1}^{m}\\textbf{x}_{i}$$\n","\n","2. mini-batch variance :\n","$$\\sigma _{B}^{2} \\leftarrow \\frac{1}{m}\\sum _{i=1}^{m}(\\textbf{x}_{i}-\\mu _{B})^{2}$$\n","\n","3. normalize :\n","$$\\hat{\\textbf{x}_{i}} \\leftarrow \\frac{\\textbf{x}_{i}-\\mu _{B}}{\\sqrt{\\sigma _{B}^{2}+\\epsilon }}$$\n","\n","4. scale and shift :\n","$$y_{i} \\leftarrow \\gamma \\hat{\\textbf{x}_{i}} + \\beta \\equiv \\text{BN}_{\\gamma ,\\beta }(\\textbf{x}_{i})$$\n","\n","위 수식을 풀어서 설명해 드리면 batch normalization은 mini-batch의 평균($\\mu _{B}$)과 분산($\\sigma _{B}^{2}$)을 구해서 입력 데이터를 정규화(normalize)하고, 이 값에 scale($\\gamma$)과 shift($\\beta$)를 추가한 것입니다. 결국 입력 데이터($\\textbf{x}_{i}$)는 batch normalization을 거쳐 ($y_{i}= \\gamma \\hat{\\textbf{x}_{i}} + \\beta$)이 됩니다.\n","\n","- 중간에 $\\epsilon$이 붙은 이유는 분산($\\sigma _{B}^{2}$)이 0일 경우 나눗셈 오류가 발생하는 것을 방지하기 위함입니다.\n","- $\\gamma$와 $\\beta$ 값은 학습 파라미터로 모델 학습이 진행되면서 가중치와 함께 업데이트됩니다."],"metadata":{"id":"BTrAbFAFJNzQ"}},{"cell_type":"markdown","source":["## 실습\n","---\n","아무것도 하지 않은 fully connected layer와 batch normalization layer를 추가한 두 실험을 비교하고자 합니다. 중점적으로 봐야 할 내용은 **정확도 비교와 속도의 차이**입니다."],"metadata":{"id":"NCrTCBvVJNvI"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torch.utils.data import DataLoader, random_split\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print('=3')"],"metadata":{"id":"K6rSIx6Hg5_r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["이미지 데이터인 fashion mnist 데이터셋을 불러오겠습니다. 총 10개의 클래스로 나누어져 있습니다."],"metadata":{"id":"303sq75NJNqw"}},{"cell_type":"code","source":["class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n","               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)"],"metadata":{"id":"QGuLd0gthek4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["이미지를 트레이닝하기 위해서 train:valid 를 7:3으로 분리하고, dense layer를 쌓아서 트레이닝 해보겠습니다."],"metadata":{"id":"EYOsp1CrJNMo"}},{"cell_type":"code","source":["train_size = int(0.7 * len(train_dataset))\n","valid_size = len(train_dataset) - train_size\n","train_data, valid_data = random_split(train_dataset, [train_size, valid_size])\n","\n","train_loader = DataLoader(train_data, batch_size=2048, shuffle=True)\n","valid_loader = DataLoader(valid_data, batch_size=2048, shuffle=False)"],"metadata":{"id":"K-n5ZcYEhek4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ComparisonModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(28*28, 128)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        return x"],"metadata":{"id":"KSmN3cBBhxDn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","model_no_bn = ComparisonModel().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model_no_bn.parameters(), lr=0.001)\n","train_loss, valid_loss, train_acc, valid_acc = train(model_no_bn, train_loader, valid_loader, criterion, optimizer, epochs=20)"],"metadata":{"id":"BzHFQ0jpkIFn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loss 값을 plot 해보겠습니다.\n","plt.plot(train_loss, label='Train Loss', color='blue')\n","plt.plot(valid_loss, label='Validation Loss', color='red')\n","plt.legend()\n","plt.title('Loss graph without batch normalization')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.grid()\n","plt.show()"],"metadata":{"id":"qdnppqUskXS3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# accuracy 값을 plot 해보겠습니다.\n","plt.plot(train_acc, label='Train Accuracy', color='blue')\n","plt.plot(valid_acc, label='Validation Accuracy', color='red')\n","plt.legend()\n","plt.title('Accuracy graph without batch normalization')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.grid()\n","plt.show()"],"metadata":{"id":"GpHq4lBZkeVX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["아래는 BatchNormalization layer를 추가한 실습입니다."],"metadata":{"id":"gFoD6SQcOXAP"}},{"cell_type":"code","source":["# Q. 두 개의 dense layer 사이에 batch normalization layer를 추가하는 코드입니다.\n","\n","class BatchNormModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # [[YOUR CODE]]\n","        # 여기에 batch normalization layer를 추가해보았습니다. 나머지 layer는 위의 실습과 같습니다.\n","        self.batch_norm = nn.BatchNorm1d(128)\n","        # [[YOUR CODE]]\n","\n","    def forward(self, x):\n","        # [[YOUR CODE]]\n","        x = self.batch_norm(x)\n","        # [[YOUR CODE]]\n","        return x"],"metadata":{"id":"mVukv0jMksm_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","model_bn = BatchNormModel().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model_bn.parameters(), lr=0.001)\n","train_loss, valid_loss, train_acc, valid_acc = train(model_bn, train_loader, valid_loader, criterion, optimizer, epochs=20)"],"metadata":{"id":"wjzZoNkpk9wf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loss 값을 plot 해보겠습니다.\n","plt.plot(train_loss, label='Train Loss', color='blue')\n","plt.plot(valid_loss, label='Validation Loss', color='red')\n","plt.legend()\n","plt.title('Loss graph with batch normalization')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.grid()\n","plt.show()"],"metadata":{"id":"_6UcHdJtlJ5_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# accuracy 값을 plot 해보겠습니다.\n","plt.plot(train_acc, label='Train Accuracy', color='blue')\n","plt.plot(valid_acc, label='Validation Accuracy', color='red')\n","plt.legend()\n","plt.title('Accuracy graph with batch normalization')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.grid()\n","plt.show()"],"metadata":{"id":"MQuOUCIhlRZn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["기존의 fully connected layer도 낮지 않은 결과를 가져오지만, batch normalization을 추가하니 좀 더 빠르게 정확도 상승이 있음을 확인할 수 있습니다. 또한 loss 함수의 감소도 더 빨라짐을 확인할 수 있었습니다. 즉 batch normalization으로 인해 데이터 분포가 정규화되면서 좀 더 고른 분포를 가지기도 하며, 모델과 함께 학습되는 $\\gamma$, $\\beta$ 파라미터로 데이터 분포를 적절하게 변환함으로써 보다 안정적인 학습이 가능해집니다."],"metadata":{"id":"RFcu8DI8Ob33"}},{"cell_type":"markdown","source":["## 종합퀴즈\n","---\n","**Q. L1 regularization과 L2 regularization의 공통점과 차이점은 무엇이었나요?**\n","\n","<details>\n","<summary>💡예시답안 확인하기💡</summary>\n","\n","[공통점]\n","두 방법 모두 Lp norm 개념을 사용하고 있고, 오버피팅이 발생하지 않도록 모델에 제약 조건을 걸어줍니다.\n","\n","\n","[차이점]\n","L1 regularization(Lasso)은 L1 norm을 사용하며, 일부 coefficient 값을 0으로 보내기 때문에 차원 축소와 비슷한 역할을 합니다.\n","\n","L2 regularization(Ridge)은 L2 norm을 사용하며, 계수를 0으로 보내지는 않지만 제곱 항이 있기 때문에 L1 regularization보다는 수렴 속도가 빠르다는 장점이 있습니다.\n","</details>"],"metadata":{"id":"sjM8gCwrOjP_"}}]}